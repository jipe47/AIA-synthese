\chapter{Méthodes d'ensemble}

Pour une méthode donnée, il y a généralement un trade-off à faire entre le biais et la variance. Il est possible d'améliorer le modèle (par exemple avec du pruning pour les arbres de décision), mais ce n'est pas toujours possible. Le but des méthodes d'ensemble est de modifier de trade-off, quitte à perdre des features de la méthode initiale.


L'idée est de combiner plusieurs modèles construits avec un algorithme d'apprentissage afin d'améliorer la précision. Les arbres de décision sont souvent utilisés pour des raisons d'efficacité.

Il existe deux familles de méthode :

\begin{itemize}
	\item les techniques de moyennage, où la prédiction finale n'est que la moyenne des prédictions, et qui permettent de surtout faire diminuer la variance.
	\item les algorithmes de boosting, où on crée des modèles séquentiellement afin de diminuer le biais.
\end{itemize}

\section{Bagging}

	\subsection{Approche théorique}
	Supposons que l'on puisse générer plusieurs échantillons d'apprentissages $\ens{\LS_1, \LS_2, \dots , \LS_T}$ à partir de la distribution des données originales $P(\xu, y)$. Pour chacun des $\LS_i$, on va apprendre un modèle $\yh_{\LS_i}$ et on va calculer la moyenne :
	
	$$\yh_{\text{ens}} = \frac{1}{T} \sum_{i = 1}^T \yh_{\LS_i}(\xu)$$
	
	Pour rappel, on a l'erreur moyenne suivante :
	\begin{eqnarray*}
	\els{\text{Err}(\xu)} & = & \eyx{(y - h_B(\xu))^2} \\
	 & + & (h_B(\xu) - \els{\yh(\xu)})^2 \\
	 & + & \els{(\yh(\xu) - \els{\yh(\xu)})^2}
	\end{eqnarray*}
	
	Le biais n'est pas différent par rapport à l'algorithme original. En effet,
	
	$$\text{E}_{\LS_1, \dots , \LS_T} \ens{\yhens (\xu)} = \frac{1}{T} \sum_i \text{E}_{\LS_i}\ens{\yh_{\LS_i}(\xu)} = \els{\yh_{\LS}(\xu)}$$
	
	Par contre, la variance est divisée par $T$ :
	
	$$\text{E}_{\LS_1, \dots , \LS_T} \ens{(\yh_{\text{ens}}(\xu) - \text{E}_{\LS_1, \dots , \LS_T} \ens{\yh_{\text{ens}}(\xu)})^2} = \frac{1}{T} \els{(\yh(\xu) - \els{\yh_{\text{ens}}(\xu)})^2}$$
	
	En effet, différents échantillons d'apprentissage conduisent à différents modèles, surtout si l'algorithme sur-apprend les données. Vu qu'il n'y a qu'un seul modèle optimal, la variance est la source d'erreur.
	
	
	\subsection{En pratique}
	
	Il n'est généralement pas possible de créer plusieurs $\LS$, car $P(\xu, y)$ est inconnu, et les méthodes d'ensembles nécessitent justement beaucoup de données. L'idée est d'utiliser du bootstrap sampling pour générer plusieurs ensembles d'apprentissage.

	\dessin{21}
	
	On a alors l'algorithme du bagging (\textbf{b}ootstrap \textbf{agg}regat\textbf{ing}) :
	
	\begin{itemize}
		\item on crée $T$ bootstrap samples $\ens{B_1, \dots , B_T}$ à partir de $\LS$
		\item on apprend un modèle $\yh_{B_i}$ pour chaque $B_i$
		\item on construit le modèle de moyenne :
		
		$$\yh_{\text{ens}}(\xu) = \frac{1}{T} \sum_{i = 1}^T \yh_{B_i}(\xu)$$
	\end{itemize}
	
	\dessinS{90}{.45}
	
	Dans le cas d'une classification, $\yh(\xu)$ sera la classe majoritaire parmi $\ens{\yh_1(\xu), \dots , \yh_T(\xu)}$

	\dessinS{92}{.45}
	
	La variance est réduite, mais le biais augmente un peu car la taille effective du bootstrap sample est environ 30\% plus petite que le $\LS$ original ; tous les exemples de départ ne s'y trouvent pas, seulement environ $\sim$ 63.2\%.
	
	\dessinS{100}{.65}
	
	L'erreur est moindre, par contre il faut souvent augmenter la complexité pour obtenir l'erreur minimale.
	
	\subsection{Autres techniques de moyennage}
	
	Paradigme de perturbation et combinaison : on perturbe les données ou l'algorithme d'apprentissage pour obtenir plusieurs modèles qui sont bons sur l'échantillon d'apprentissage, puis on combine les prédictions des modèles.
	
	La variance est généralement diminuée (grâce à la moyenne), mais le biais augmente un peu à cause de la perturbation.
	
	Exemples : le bagging perturbe l'échantillon d'apprentissage, les réseaux de neurones peuvent être initialisés avec des poids aléatoires, random forests
	
\section{Random Forests}

	C'est un algorithme de type \textit{perturb and combine} conçu spécifiquement pour les arbres. Elle utilise du bagging et une sélection aléatoire d'un ensemble d'attributs. L'algorithme suivant est utilisé :
	
	\begin{itemize}
		\item on construit l'arbre sur un bootstrap sample
		\item au lieu de choisir le meilleur split sur tous les attributs (au nombre de $p$), on sélectionne le meilleur split parmi un sous-ensemble de $k$ attributs
	\end{itemize}
	
	Il y a un trade-off biais/variance avec $k$ : plus $k$ est petit et plus la réduction est grande, mais plus haut sera le biais. Faire la moyenne casse le compromis biais/variance habituel.
	
	Le fait d'effectuer des choix aléatoires fait que l'arbre ne dépend pas de l'échantillon d'apprentissage
	
	\dessinS{93}{.5}
	
	Un autre avantage des random forests est de diminuer le temps de calcul par rapport au bagging, car seul un sous-ensemble d'attributs est considéré lorsqu'on split un noeud (et pas tous). Généralement, $k = \sqrt{p}$.
	
	
\section{Décomposition de l'ambiguïté}

Supposons que l'on ait $T$ modèles $\ens{\yh_1, \dots , \yh_T}$ et leur moyenne

$$\yhens(\xu) = \frac{1}{T} \sum_i \yh_i(\xu)$$

\begin{eqnarray*}
\frac{1}{T} \sum_i \eyx{(y - \yh(\xu))^2} & = & \frac{1}{T} \sum_i \eyx{(y - \yens(\xu) + \yens(\xu) - \yh_i(\xu))^2} \\
& = & \frac{1}{T} \sum_i \eyx{(y - \yens(\xu))^2} \\
& + & \frac{1}{T} \sum_i \underbrace{\eyx{(\yens(\xu) - \yh_i(\xu))^2)}}_{\star_1} \\
& + & \underbrace{\frac{1}{T} \sum_i \eyx{\underbrace{(y(\xu) - \yens(\xu))}_{\substack{\text{ne dépend} \\ \text{pas de }i}}
\underbrace{(\yens(\xu) - \yh_i(\xu))}_{\substack{\text{ne dépend} \\
 \text{pas de } y}}}}_{\eyx{y - \yens(\xu)}\frac{1}{T} \sum_i (\yens(\xu) - \yh_i(\xu)) \star_2} \\
\end{eqnarray*}
 
 $\star_1$ : on peut supprimer le $\eyx{.}$ car l'intérieur ne dépend pas de $y$. De plus, on a que $\yens = \frac{1}{T} \sum_i \yh_i(\xu)$
 
 $\star_2$ : $\yens(\xu)$ ne dépend pas de $i$, donc on peut faire rentrer la somme et annuler le terme car $\sum_i \yh_i(\xu) = \yens(\xu)$.
 
 Au final, on a

\begin{eqnarray*}
& \frac{1}{T}\sum_i \eyx{(y - \yh_i(\xu))^2} & = \eyx{(y - \yhens(\xu))^2} + \frac{1}{T} \sum_i (y_i(\xu) - \yhens(\xu))^2 \\
\Leftrightarrow & \underbrace{\eyx{(y - \yhens(\xu))^2}}_{\substack{\text{Erreur de la} \\ \text{méthode d'ensemble}}} & = \underbrace{\frac{1}{T}\sum_i \eyx{(y - \yh_i(\xu))^2}}_{\substack{\text{Moyenne des} \\ \text{erreurs des modèles}}} - \underbrace{\frac{1}{T} \sum_i (y_i(\xu) - \yhens(\xu))^2}_{\substack{\text{Ambiguïté de la} \\ \text{méthode d'ensemble}}}
\end{eqnarray*}

L'ambiguïté mesure la variabilité des prédictions des modèles individuels. A moins que tous les modèles ne soient les mêmes, ce terme sera toujours positif. Du coup, plus les sous-modèles sont diversifiés et plus l'ambiguïté sera grande, donc plus la méthode d'ensemble sera efficace.

Le modèle moyen est donc toujours meilleur que les modèles individuels en moyenne. Ce n'est cependant pas vrai en classification.
	
\section{Boosting}
	
L'idée est de combiner plusieurs modèles "faibles", afin de produire un modèle plus puissant. Un modèle est considéré comme faible s'il a un grand biais (en classification, si le modèle est à peine meilleur qu'un choix aléatoire).

Les différences par rapport aux autres méthodes d'ensemble sont que

\begin{itemize}
	\item les modèles sont construits séquentiellement sur des versions modifiées des données
	\item les prédictions des modèles sont combinées à travers une somme pondérée/un vote
\end{itemize}

\dessinS{94}{.5}

Par exemple, pour passer de $\LS_1$ à $\LS_2$, on ignore les points bien classés de $\LS_1$.

En régression,

$$\yh(\xu) = \beta_1\yh_1(\xu) + \dots + \beta_T \yh_T(\xu)$$

En classification, $\yh(\xu)$ sera la classe majoritaire dans $\ens{\yh_1(\xu), \dots , \yh_T(\xu)}$, en tenant compte des points $\ens{\beta_1, \dots , \beta_T}$.

	\subsection{Adaboost}
	
	On suppose que l'algorithme d'apprentissage utilisé accepte les objets pondérés : $\ens{(x_1, y_1, w_1), \dots , (x_N, y_N, w_N)}$. C'est le cas de beaucoup d'algorithmes ; avec les arbres, on prend en compte les poids quand on compte les objets ; avec un réseau de neurones, on minimise l'erreur au carré pondérée.
	
	A chaque étape, Adaboost augmente les poids dans le cas où l'échantillon est mal classé par le modèle, ainsi l'algorithme se focalise sur les cas compliqués de l'échantillon d'apprentissage. $\beta_i$ sera ainsi plus petit si le modèle commet beaucoup d'erreurs. Par exemple,
	
	\begin{itemize}
		\item si l'exemple est mal classé, $w_i \rightarrow w_i \exp{\beta}$
		\item si l'exemple est bien classé, $w_i \rightarrow w_i . 1$
	\end{itemize}
	
	On a l'algorithme suivant : il prend en entrée un algorithme d'apprentissage et un échantillon d'apprentissage $\ens{(x_i, y_i) : i = 1, \dots , N}$. On initialise les poids $w_i = \frac{1}{N}$, $i = 1 , \dots , N$.
	
	Pour $t = 1$ jusque $T$ :
	
	\begin{itemize}
		\item on construit un modèle $\yh_t(x)$ avec l'algorithme d'apprentissage en utilisant les poids $w_i$
		\item on calcule l'erreur pondérée :
		
		$$\text{Err}_t = \frac{\sum_i w_i . I(y_i \neq \yh_t(x_i))}{\sum_i w_i}$$
		
		\item on calcule $\beta_t = \log{\frac{1 - \text{Err}_t}{\text{Err}_t}}$
		\item on met à jour les poids :
		
		$$w_i \leftarrow w_i . \exp{\beta_t . I(y_i \neq \yh_t(x_i))}$$
		
		\item on normalise les poids, de façon à ce que $\sum_i w_i = 1$
	\end{itemize}
	
	\dessinS{101}{.5}
		
	\subsection{Boosting aux moindres carrés}
	
	Cet algorithme de boosting est conçu pour les régression. Il prend en entrée un algorithme d'apprentissage et un échantillon d'apprentissage $\ens{(x_i, y_i) : i = 1, \dots , N}$. On initialise de la façon suivante :
	
	$$\yh_0(x) = \frac{1}{N} \sum_i y_i$$
	$$r_i = y_i, \: i = 1, \dots , N$$
	
	
	Pour $t = 1$ jusque $T$ :
	
	\begin{itemize}
		\item pour $i = 1$ jusque $N$, on calcule les résiduels :
		
		$$r_i \leftarrow r_1 - \yh_{t - 1}(x_i)$$
		
		\item on construit un arbre de régression sur l'échantillon d'apprentissage
	\end{itemize}
	
	On retourne ensuite le modèle définit par
	
	$$\yh(x) = \yh_0(x) + \yh_1(x) + \dots + \yh_T(x)$$
	
	
	\subsection{Algorithme de boosting générique}
	
	Le but est de trouver $\yh(\xu) = \beta_1 \yh_1(\xu) + \dots + \beta_T \yh_T(\xu)$ et qui minimise $\sum_{i = 1}^N L(y_i, \yh(\xu_i))$.
	
	On utilise du \textit{forward stage-wise additive modeling} :
	
	\begin{enumerate}
		\item On initialise $\yh(\xu) = 0$
		\item pour $t = 1$ jusque $T$ :
		
		\begin{enumerate}
			\item on calcule
			
			$$(\beta_t, \yh_t) = arg \min_{\beta, \yh'} \sum_i L(y_i, \yh(\xu_i) + \beta \yh'(\xu_i))$$
			\item 
			
			$$\yh(\xu) \leftarrow \yh(\xu) + \beta_t \yh_t(\xu)$$
		\end{enumerate}
	\end{enumerate}
	
	On a ainsi
	
	\begin{itemize}
		\item pour le boosting aux moindres carrés, $L(y, y') = (y - y')^2$
		\item pour Adaboost, $L(y, y') = \exp{(-y y')}$
	\end{itemize}
	
	\dessinS{102}{.45}
	
	La courbe rouge (squared error) n'est pas intéressante, car elle pénalise les modèles où $y.f > 1$, or il faudrait qu'elle tende vers 0 comme les autres.
	
	\subsection{$\LS$ boosting}

	\remarque{Je n'ai pas retrouvé dans les transparents quoi que ce soit qui ait un rapport à cette section. Cela vient de mes notes, mais elles sont assez lacunaires, du coup ce qui suit ne veut pas dire grand chose.}
		
	On a un paramètre $u \in [0, 1]$ qui permet de ralentir l'évolution de l'algorithme, et donc le sur-apprentissage.
	
	\begin{center}
	\begin{tabular}{ccc|ccc}
	$x_1$ & \dots & $x_p$ & $y$ & $y_0$ & $y_1$ \\ 
	\hline 
	  &   &   & $y_1$ & $y_1 - u\yo$ & ? \\ 
	  &   &   & $y_2$ & $y_2 - u\yo$ & ? \\ 
	  &   &  & \vdots & \vdots & ? \\ 
	\end{tabular} 
	\end{center}
	
	Donc, à chaque itération $i$, on utilise ce qui a été obtenu à l'itération $i - 1$ avec un vecteur $u$, comme on ferait avec une moyenne exponentielle.
	
	\subsection{Autres méthodes de boosting}
	
	Il existe de nombreux autres algorithmes de boosting (par exemple le gradient boosting).
	
	Le boosting sur les arbres de décision/régression améliore très fortement leur précision, cependant on est beaucoup plus sensible au bruit (sur-apprentissage) que les techniques de moyennage.
	
	Pour que le boosting fonctionne, il faut que les modèles ne soient pas parfaits sur l'échantillon d'apprentissage. Pour les arbres, on peut soit les élaguer (pre-prune ou post-prune avec de la validation croisée), soit limiter le nombre de tests (et spliter d'abord sur les noeuds les plus impures). Il y a encore une fois un trade-off biais/variance qui dépend de la taille de l'arbre.
	
\section{Interprétabilité et efficacité}
	
Lorsque les méthodes d'ensemble sont combinées avec les arbres de décision, ils perdent de l'interprétabilité et de l'efficacité. En revanche, on les utilise toujours pour calculer l'importance des variables, en effectuant la moyenne sur tous les arbres. De plus, les méthodes d'ensemble peuvent être parallélisées et l'algorithme boosting utilise des petits arbres, ce qui fait que le coût en temps processeur n'est pas important.
		
	\dessinS{91}{.45}
	
\section{Autres approches d'ensemble}

	\subsection{Moyenne de modèles de Bayes}
	$$P(y \vert x, \LS) = \sum_{u \in \mathcal{H}} P(y \vert h, \LS) P(h \vert \LS)$$
	
	$$P(h \vert \LS) \propto P(h) P(\LS \vert h) \propto P(h) \sum_\theta P(\LS \vert \theta, h) P(\theta \vert h)$$
	
	\subsection{Stacking}
	
	On apprend un modèle qui combine des modèles. Soit $\LS = \ens{(x_i, y_i) : i = 1, \dots , N}$ et soit $A^T$ ($t = 0, \dots , T$) $T + 1$ algorithmes d'apprentissage.
	
	Pour $t = 1, \dots , T$ :
	
	\begin{itemize}
		\item construire un modèle :
		
		$$\yh^t = A^t(\LS)$$
		
		\item calculer les prédictions :
		
		$$\yh_i^t = \yh^t (x_i)$$
	\end{itemize}
	
	Soit $\LS^0 = \ens{(x_i^0, y_i)}$ avec $x_i^0 = (y_i^t)^T_{t = 1}$ : on retourne $\yh = A^0(\LS^0)$.
	
	Il s'agit d'une généralisation du boosting, dont le modèle est une combinaison linéaire des osus-modèles. L'algorithme d'apprentissage s'entraîne sur les sorties des sous-modèles.
	
	\dessin{103}
	
	Lors de la phase d'apprentissage des sous-modèles, il faut que les $y_i$ soient différents, par exemple avec de la validation croisée.
	
	\dessin{104}
	
\section{Conclusion}

Les méthodes d'ensemble sont très efficaces pour réduire le biais et/ou la variance, en transformant une méthode pas si bonne en une méthode très compétitive. Adaboost avec des arbres est considéré comme un des meilleurs algorithme de classification.

L'interprétabilité et l'efficacité du modèle sont difficiles à préserver si on veut réduire la variance significativement.