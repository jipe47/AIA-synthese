\chapter{Méthodes linéaires}

	\section{Introduction}
	Le but est de trouver un modèle qui est une combinaison linéaire des entrées.

	\begin{itemize}
		\item Pour une régression, $y = w_0 + w_1 x_1 + w_2 x_2 + \dots + w_n x_n$
		\item Pour une classification, $y = c_1$ si $w_0 + w_1 x_1 + w_2 x_2 + \dots + w_n x_n > 0$, $c_2$ sinon.
	\end{itemize}

	\dessin{13}

	Plusieurs méthodes existent pour trouver les coefficients $w_i$ : 

	\begin{itemize}
		\item Régression : least-square regression, ridge regression, partial least square, support vector regression, LASSO, \dots
		\item Classification : linear discriminant analysis, PLS-discriminant analysis, support vector machines, \dots \\
	\end{itemize} 

	Avantages et inconvénients :
	
	\begin{itemize}
		\item[+] simple ;
		\item[+] il existe des variantes rapides et scalables ;
		\item[+] cette méthode offre des modèles interprétatifs, à travers des poids variables (magnitude et signe) ;
		\item[-] parfois pas aussi précis que d'autres méthodes (non linéaires).
	\end{itemize}

	\section{Ridge regression}
	
	Une régression linéaire essaie d'approximer la sortie avec
	
	$$\yh(o) = w_0 + \sum_{i = 1}^n w_i a_i(o)$$
	
	Si on pose $a_0(o) = 1 \: \forall o$, et si on dénote
	
	\begin{itemize}
		\item $\ab'(o) = (a_0(o), a_1(o), \dots , a_n(o))^T$, et
		\item $\wb' = (w_0, w_1, \dots , w_n)^T$,
	\end{itemize}
	
	On a 
	
	$$\yh(o) = \wb'^T\ab'(o)$$
	
	Le carré de l'erreur (Square Error) sur un échantillon $i$ peut s'écrire :
	
	$$SE(o_i, \wb') = (y(o_i) - \yh(o_i))^2 = (y(o_i) - \wb'^T\ab'(o_i))^2$$
	
	On a aussi le carré de l'erreur sur tous les objets de $LS$ (Total Square Error), avec $A' = (\ab'_1, \dots , \ab'_N)$ et $\yb = (y(o_1), y(o_2), \dots , y(o_N))$ :
	
	$$TSE(LS, \wb') = \sum_{i = 1}^N (y(o_i) - \wb'^T\ab'(o_i))^2 = (\yb - A'^T\wb')^T(\yb - A'^T\wb')$$
	
	avec
	
	$$A' = \begin{array}{c}\left. \underbrace{\begin{pmatrix}
	1 & 1 & \dots & 1 \\ 
	a_1(o_1) & a_2(o_1) & \dots & a_N(o_1) \\ 
	\vdots & \dots & \dots & \vdots \\ 
	a_1(o_n) & a_2(o_n) & \dots & a_N(o_n)
	\end{pmatrix}}_{N}\right\} n + 1\end{array} $$
	
		
	On cherche $\wb'$ qui minimise
		
	$$\TSE(\LS, \wb') = (\yb - A'^T\wb')^T(\yb - A'^T\wb')$$
		
	Le gradient est
		
	$$\Delta_{w'} TSE(\LS, \wb') = -2 A' (\yb - A'^T\wb')$$
		
	Si on résout $\Delta_{w'} TSE(\LS, \wb') = 0$, on obtient
	
	\begin{eqnarray*}
	& 0 = & -2A'\yb + 2A'A'^T\wb' \\
	\Leftrightarrow & 2A'\yb = & 2A'A'^T\wb' \\
	\Leftrightarrow & \wb' = & (A'A'^T)^{-1}A'\yb
	\end{eqnarray*}
		
		
	Il existe cependant plusieurs solutions optimales, ce n'est pas un problème à solution unique. Afin d'avoir une solution unique, on va introduire un terme $\lambda > 0$ de régulation : l'erreur régulée vaut
	
	$$\TSE_R(\LS, \wb') = (\yb - A'^T\wb)^T(\yb - A'^T\wb') + \textcolor{red}{\lambda \wb'^T\wb'}$$
	
	Le gradient devient
	
	$$\Delta_{w'} TSE_R(\LS, \lambda, \wb') = -2 A' (\yb - A'^T\wb') + \textcolor{red}{2 \lambda \wb'}$$
	
	La solution optimale devient alors
	
	$$\wb^*(\lambda) = (A' A'^T + \textcolor{red}{\lambda I})^{-1} A \yb$$
	
	Cette solution est unique $\forall \lambda > 0$. Augmenter $\lambda$ réduit la variance, car on tient moins compte de $A'$ dans $TSE_R$. En revanche, on est moins optimal sur l'échantillon, il y a augmentation de l'erreur quadratique moyenne.
		
	\dessin{39}
		
	Augmenter $\lambda$ est bénéfique sur un échantillon de test indépendant.
	
	En terme de temps de calcul :
	
	\begin{itemize}
		\item créer la matrice de covariance est de l'ordre de $N n^2$ opérations
		\item résoudre le système pour trouver $\wb^*$ est de l'ordre de $n^3$ opérations
		\item[$\rightarrow$] $\bigoh(n^3)$
	\end{itemize}
	
	
	C'est la méthode de régulation qui donne son nom à la \textit{ridge regression}
	
	
\section{Perceptron}
	
L'intuition derrière le perceptron est qu'un cerveau humain peut apprendre, et qu'on pourrait s'en inspirer pour développer un algorithme. Ainsi, un perceptron est la modélisation d'un neurone, qui va ensuite former des couches pour créer des réseaux de neurones.
	
\dessinS{111}{.3}
	
La sortie est une somme pondérée des entrées. Le seul paramètre à adapter au problème est $\wb'$/$\wb$, qui doit minimiser
	
$$\sum_i (y_i - wx_i)^2$$

en utilisant une descente de gradient : étant donné un exemple d'entrainement $(x, y)$,

$$\delta \leftarrow y - w^Tx$$
$$w_j \leftarrow w_j + \eta \delta x_j \: \forall j$$

Il s'agit d'un algorithme de type \textit{online}, c'est-à-dire qu'il traite les exemples un à un, alors qu'un algorithme de type \textit{batch} traite tous les exemples en une seule fois.

La complexité est régulée par le taux d'apprentissage $\eta$ et le nombre d'itérations.

	\subsection{Algorithme du perceptron}
	
	Pour de la classification binaire, on pose que $c(o) = \pm 1$. On définit $\eta_i$ le taux d'apprentissage.
	
	\begin{itemize}
		\item on commence avec un vecteur de poids initial arbitraire, par exemple $\wb_0' = \textbf{0}$.
		\item on considère chaque élément de $\LS$ dans une séquence cyclique ou aléatoire
		
		\item soit l'objet $o_i$ l'objet à l'étape $i$, $c(o_i)$ est sa classe et $\ab(o_i)$ son vecteur d'attributs
		\item si l'objet $o_i$ est mal classé, on ajuste le vecteur de poids avec la règle suivante :
		
		$$\wb_{i + 1}' = \wb_i' + \eta_i (c(o_i) - g(\ab(o_i))) \ab'(o_i)$$
	\end{itemize}
	
	% Slide 9/21 : vue géométrique, que je n'arrive pas à comprendre
	
	\subsection{Soft threshold units}
	
	La fonction d'entrée/sortie $g(\ab)$ est donnée par
	
	$$g(\ab(o)) \triangleq f(w_0 + \wb^T\ab(o)) = f(\wb'^T \ab'(o))$$
	
	$f(.)$ est une fonction d'activation qui est supposée dérivable. On a généralement pour cette fonction
	
	\begin{itemize}
		\item une sigmoïde :
		
		$$sigmoid(x) = \frac{1}{1 + \exp(-x)}$$
		
		\dessin{118}
		
		\item une tangente hyperbolique :
		
		$$tanh(x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(-x)}$$
		
		\dessin{117}
		
		\item la fonction $sgn$
		
		\dessin{119}
		
	\end{itemize}
	
	\subsection{Descente de gradient}
	
	Slides 11 et 12/21
	
	\subsection{Propriétés}
	
	Si $\LS$ est linéairement séparable, l'algorithme convergera en un nombre fini d'étape. Sinon, il convergera avec un nombre infini d'étape si $\eta_i \rightarrow 0$.
	
	Résultats théoriques de l'algorithme de descente de gradient : 13/21
	
	\subsection{Couche de perceptrons}
	
	On considère des perceptrons mis côte à côte. Ils ont tous en entrée tous les attributs des objets et fonctionnent de manière indépendante. Par exemple, on pourrait avoir le réseau suivant qui permet d'effectuer une classification parmi quatre classes ; chaque neurone code un bit de la classe.
	
	\dessinS{112}{.45}
	
	Cela ne fonctionne toujours que dans le cas de problèmes linéairement séparables, sinon il faut considérer plusieurs couches afin d'obtenir un modèle non linéaire

\section{Réseaux de neurones}

Les réseaux de neurones ont le pouvoir de représentation universel : on peut tout représenter (à un $\sigma$ près) pour autant qu'on a suffisamment de neurones et de couches.

Un réseau est composé d'au moins une couche d'entrée et d'une couche de sortie, les couches situées entre les deux sont appelées les couches cachées. Chaque neurone est relié à tous les neurones de la couche précédente.

	\subsection{Classification}
	
	On considère généralement trois couches :
	
	\begin{enumerate}
		\item la première peut définir un ensemble d'hyper/demi-plans
		\item la seconde peut définir des intersections d'hyper/demi-plans
		\item la troisième peut définir des unions d'intersections
	\end{enumerate}
	
	\dessinS{113}{.65}
	
	\subsection{Régression}
	
	On considère deux couches :
	
	\begin{itemize}
		\item la première définit $K$ paramètres d'offset $\beta_i$ et de scale $\alpha_i$ : les réponses sont $f(\alpha_i x + \beta_i)$ avec $i = 1, \dots , K$
		\item la seconde couche est une linéarisation :
		
		$$\yh(x) = b_0 + \sum_{i = 1}^K b_i f(\alpha_i x + \beta_i)$$
	\end{itemize}
	
	\dessinS{114}{.5}
	
	Plus on a de neurones et plus on peut approximer des fonctions continues, avec un $K$ suffisamment grand. La phase d'apprentissage permet d'ajuster les paramètres des fonctions.
	
	\subsection{Apprentissage d'un réseau multi-couche}
	
	On utilise la propagation arrière des dérivations : on commence l'apprentissage à partir de la dernière couche pour revenir à la première. L'idée est de calculer les dérivations de la fonction d'erreur (au sens des moindres carrés) en partant de la couche de sortie jusqu'à la couche d'entrée, ce qui a pour but de réduire la fonction d'erreur en modifiant les poids.
	
	On a l'algorithme suivant pour un réseau de trois couches : % From http://en.wikipedia.org/wiki/Backpropagation
	
	\begin{itemize}
		\item initialiser les poids du réseau (généralement aléatoirement)
		\item tant que les exemples ne sont pas correctement classés ou qu'un critère n'est pas satisfait :
		
		\begin{itemize}
			\item pour chaque exemple $e$ de l'ensemble d'apprentissage
				\begin{itemize}
					\item soit $o$ la sortie du réseau de neurones pour l'entrée $e$ (forward pass) et $t$ la "vraie" sortie de $e$ (donnée de l'ensemble d'apprentissage)
					\item calculer l'erreur $t - o$
					\item calculer les deltas pour tous les poids des synapses qui vont de la couche cachée à la couche de sortie (backward pass)
					\item calculer les deltas pour tous les poids des synapses qui vont de la couche d'entrée vers la couche cachée (backward pass continued)
					\item mettre à jour les poids du réseau
				\end{itemize}
		\end{itemize}
	\end{itemize}
	
	
\section{Méthodes de régression à base de noyaux}
	
Un noyau $K(., .)$ est une fonction qui exprime la similarité de deux objets à travers une valeur numérique. Pour tout noyau $K$ il existe une fonction $\phi$ telle que $K(o, o') = \phi(o) \times \phi(o')$.

Lorsqu'on utilise la régression au sens des moindres carrés avec des noyaux, on a un modèle de la forme

$$\yh(x) = w^T \phi(x) + b$$

où on cherche $w$ et $b$ qui minimisent la fonction d'erreur

$$\text{Err}(w, b) = \frac{1}{2} w^T w + \frac{1}{2} \sum_{k = 1}^N \underbrace{(y_k - (w^T \phi(x_k) + b))^2}_{e_k}$$

C'est un problème d'optimisation sous contraintes. En passant par le lagrangien on a

\begin{eqnarray*}
w & = & \sum_{j = 1}^N \alpha_j \phi(x_j) \\
\alpha_k & = & y e_k \\
\sum_{k = 1}^N \alpha_k & = & 0
\end{eqnarray*}

On a donc

$$e_k = y_k - (b + \sum_{j = 1}^N \alpha_j K(x_j, x_k))$$

Si on réintroduit $e_k$ dans l'équation 2, on a

$$\yh(x) = b + \sum_{i = 1}^N \alpha_i K(x, x_i)$$

avec $K$ une matrice définie par $K_{i, j} = K(x_i, x_j)$. Cela revient à écrire

$$\begin{pmatrix}
0 & 1 & \dots & 1 \\ 
1 &   &   &   \\ 
\vdots &   & K + \gamma^{-1}l &   \\ 
1 &   &   &  
\end{pmatrix} \begin{pmatrix}
b \\ 
\alpha_1 \\ 
\vdots \\ 
\alpha_N
\end{pmatrix} = \begin{pmatrix}
0 \\ 
y_1 \\ 
\vdots \\ 
y_N
\end{pmatrix} $$


L'algorithme d'apprentissage va alors utiliser les valeurs de la matrice $K$ et $y_k$ pour déterminer les $\alpha_i$ et $b$. Au final, on n'a pas besoin de connaître $\phi(x)$.

Au niveau de la complexité, on a 

\begin{itemize}
	\item $N^3$ opérations pour l'apprentissage
	\item $N$ opérations pour la prédiction
\end{itemize}

	


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   _____                                          _      
%  / ____|                                        | |     
% | (___   ___  _   _ _ __ ___ ___    ___ ___   __| | ___ 
%  \___ \ / _ \| | | | '__/ __/ _ \  / __/ _ \ / _` |/ _ \
%  ____) | (_) | |_| | | | (_|  __/ | (_| (_) | (_| |  __/
% |_____/ \___/ \__,_|_|  \___\___|  \___\___/ \__,_|\___|
% | |              | |                                    
% | |__   __ _  ___| | ___   _ _ __                       
% | '_ \ / _` |/ __| |/ / | | | '_ \                      
% | |_) | (_| | (__|   <| |_| | |_) |                     
% |_.__/ \__,_|\___|_|\_\\__,_| .__/                      
%                             | |                         
%                             |_| 
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
	% Ce qui suit est un résumé des slides du cours à partir du 10/19. Vu que ce n'est pas spécialement accessible ni amusant, le lecteur peut aller en parler à Denver à la fin de ce fichier.
		
	\begin{comment}
	[slide 10/19]
		
	Considérons la matrice $(A'A'^T)$ : l'élément $i, j$ est obtenu par le produit scalaire de la $i$ème ligne et de la $j$ ème ligne de $A'$ :
		
	$$A'A'^T = N \begin{pmatrix}
		1 &  \ao_1 & \dots & \ao_n \\ 
		\ao_1 & g_{1,1} & \dots & g_{1, n} \\
		\vdots & \vdots & \ddots & \vdots \\
		\ao_n & g_{n, 1} & \dots & g_{n, n}
		\end{pmatrix} $$
		
	avec $\ao_i = \frac{1}{N} \sum_{k = 1}^N a_i(o_k)$ et $g_{i, j} = \frac{1}{N} \sum_{k = 1}^N a_i(o_k)a_j(o_k)$.
		
	Si la moyenne est nulle, $\ao_i = 0$ et les $g_{i, j}$ forment la matrice de covariance $\Sigma$
		
	\remarque{slides 12-19/19 ; ce qui suit vient de mes notes manuscrites}
		
	En conclusion, la prédiction n'est pas modifiée si on ajoute des constantes et si on effectue des combinaisons linéaires aux valeurs des attributs (tant qu'elles ne sont pas singulières).
		
	Si on retire la moyenne et l'écart-type à tous les coefficients de la matrice, on les place dans le même ordre de grandeur (abstraction des unités).
				
	Le problème est que plusieurs solutions sont possible. La solution est d'utiliser $\lambda$ [slide 16/19], qui permet d'en isoler une et de mieux conditionner le problème.
		
	Augmenter $\lambda$ réduit la variance, car on tient moins compte de $A$ dans $TSE_R$. En revanche, on est moins optimal sur l'échantillon, il y a augmentation de l'erreur quadratique moyenne.
		
	\dessin{39}
		
	Augmenter $\lambda$ est bénéfique sur un échantillon de test indépendant.
		
	\end{comment}
		
		
		
	% Ce qui suit appartiennait à une première version de la synthèse, qui commencait par résumer l'overview.
	
	\begin{comment}
	\section{Extensions non linéaires}

	Plusieurs extensions existent :

	\begin{itemize}
		\item la généralisation des méthodes linéaires :
	
		$$y = w_0 + w_1 \phi_1(x_1) + w_2 \phi_2(x_2) + \dots + w_n \phi_n(x_n)$$
	
		N'importe quelle méthode linéaire peut être appliquée, mais la régulation devient plus importante.
	
		\item Réseaux de neurones artificiels, avec une seule couche cachée : si $g$ est une fonction non linéaire (par exemple une sigmoid),
	
		$$y = g(\sum_j w_J g(\sum_i w_{i, j} x_i))$$
	
		C'est une fonction non linéaire d'une combinaison linéaire de fonction non linéaires de combinaisons linéaires d'entrées.
	
		\item Méthode à base de noyaux :
	
		$$y = \sum_i w_i \phi_i(x) \Leftrightarrow y = \sum_j \alpha_j k(x_j, x)$$
	
		où $k(x, x') = \langle \phi(x), \phi(x') \rangle$, le produit scalaire dans l'espace donné et où $j$ indexe les exemples d'entraînement du modèle.
	\end{itemize}

	\end{comment}
		
% Ce qui suit vient d'une première synthèse basée sur l'overview. Ce n'est plus pertinent de l'inclure dans cette synthèse, mais le code est conservé au cas où il faudrait effectuer quelques prélèvements.

\begin{comment}
\subsection{Modèle linéaire}

\dessin{3}

On a par exemple

$$h(X_1, X_2) = \left\{
\begin{array}{ll}
\text{malade} & \text{si } w_0 + w_1X_1 + w_2X_2 > 0 \\
\text{sain} & \text{sinon.}
\end{array}
\right.$$

La phase d'apprentissage aura pour but de trouver les meilleurs $w_0$, $w_1$ et $w_2$ ; un modèle linéaire ne possède que trois paramètres.

\subsection{Modèle quadratique}
\dessin{4}

$$h(X_1, X_2) = \left\{
\begin{array}{ll}
\text{malade} & \text{si } w_0 + w_1X_1 + w_2X_2 + \textcolor{red}{w_3 X_1^2 + W_4X_2^2} > 0 \\
\text{sain} & \text{sinon.}
\end{array}
\right.$$

La phase d'apprentissage aura pour but de trouver les meilleurs $w_0$, $w_1$, $w_2$, $w_3$ et $w_4$.

Par facilité, on peut étendre la base de données, en ajoutant des colonnes contenant $X_1^2$ et $X_2^2$.

Un modèle quadratique est au moins aussi bon que le meilleur modèle linéaire, car on peut rendre un modèle quadratique linéaire avec $w_3 = w_4 = 0$.


\subsection{Modèle d'un réseau de neurones artificiels}
\dessin{5}
$$h(X_1, X_2) = \left\{
\begin{array}{ll}
\text{malade} & \text{si une fonction complexe de } X_1, X_2 > 0 \\
\text{sain} & \text{sinon.}
\end{array}
\right.$$
La phase d'apprentissage aura pour but de trouver les paramètres numériques de cette fonction.

\end{comment}


%           _                  
%          //                                                  
%         //                                                   
%      __/(                                                    
%  _.~-a  ~-.                                                  
% {_____)    `.           _..=~~~~=._                          
%       ~-_    \      _.=~           '=.                       
%          \    `._.=~            .=.   :=._                   
%           -         __         (   \   : \)                  
%            ~.      (  }       (     |   : :                  
%              `:     \ \        \    |\   ; :                 
%                \     \ }        \   / |  ;  }                
%                 `-.__//__.==~~=._\ (_/  ;  ;                 
%                     //           | |/  ;  ;                  
%                    {{       _____|_/ ;   ;        *     ___  
%                     `      ---- _=.=`   ~ _____   ||*    ____
%                             __:='    .='     ___\\||/___     
%                         ..:~____.==''                        